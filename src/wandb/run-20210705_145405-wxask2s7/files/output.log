2021-07-05 14:54:06,670 [INFO] {'data_dir': '../data', 'no_cuda': False, 'debug': True, 'log_batch_size': 7, 'epochs': 10, 'data_type': 'matres', 'finetune': False, 'model': 'box', 'downsample': 0.001, 'learning_rate': 0.01, 'lambda_anno': 1.0, 'lambda_trans': 0.0, 'lambda_cross': 0.0, 'volume_temp': 1.0, 'intersection_temp': 0.0001, 'hieve_threshold': -0.6, 'matres_threshold': -0.5, 'mlp_size': 32, 'mlp_output_dim': 32, 'hieve_mlp_size': 64, 'matres_mlp_size': 32, 'proj_output_dim': 32, 'num_layers': 1, 'roberta_hidden_size': 1024, 'lstm_hidden_size': 256, 'lstm_input_size': 768, 'no_valid': False, 'loss_type': 0, 'patience': 8, 'eval_step': 1, 'eval_type': 'one', 'load_model': 0, 'saved_model': '/Users/ehwang/PycharmProjects/CE2ERE/src/model/matres_20210505163300_2ya6wb7v.pt', 'wandb_id': 'hwang7520/CE2ERE-src/2ya6wb7v', 'load_valid': 0, 'save_plot': 1, 'symm_eval': 1}
2021-07-05 14:54:06,671 [INFO] Requested CUDA but it is not available, running on CPU
  0%|          | 0/274 [00:00<?, ?it/s]  0%|          | 1/274 [00:00<00:48,  5.60it/s]  1%|          | 3/274 [00:00<00:45,  5.96it/s]  2%|▏         | 5/274 [00:00<00:36,  7.35it/s]  3%|▎         | 7/274 [00:00<00:36,  7.33it/s]  3%|▎         | 9/274 [00:01<00:33,  8.00it/s]  4%|▍         | 11/274 [00:01<00:59,  4.39it/s]  4%|▍         | 12/274 [00:02<01:00,  4.34it/s]  5%|▌         | 14/274 [00:02<00:46,  5.55it/s]  5%|▌         | 15/274 [00:02<00:41,  6.22it/s]  6%|▌         | 17/274 [00:02<00:33,  7.62it/s]  7%|▋         | 20/274 [00:02<00:27,  9.16it/s]  8%|▊         | 23/274 [00:02<00:22, 11.02it/s]  9%|▉         | 25/274 [00:03<00:24, 10.00it/s] 10%|▉         | 27/274 [00:03<00:25,  9.56it/s] 11%|█         | 29/274 [00:03<00:27,  8.96it/s] 11%|█▏        | 31/274 [00:04<00:32,  7.54it/s] 12%|█▏        | 32/274 [00:04<00:43,  5.61it/s] 12%|█▏        | 34/274 [00:04<00:35,  6.70it/s] 14%|█▎        | 37/274 [00:04<00:27,  8.67it/s] 14%|█▍        | 39/274 [00:04<00:23, 10.01it/s] 15%|█▍        | 41/274 [00:04<00:25,  9.16it/s] 16%|█▌        | 44/274 [00:05<00:20, 11.28it/s] 17%|█▋        | 46/274 [00:05<00:19, 11.82it/s] 18%|█▊        | 48/274 [00:05<00:19, 11.39it/s] 19%|█▊        | 51/274 [00:05<00:17, 13.11it/s] 19%|█▉        | 53/274 [00:06<00:32,  6.76it/s] 20%|██        | 55/274 [00:06<00:34,  6.33it/s] 21%|██        | 57/274 [00:06<00:37,  5.76it/s] 22%|██▏       | 59/274 [00:07<00:36,  5.81it/s] 22%|██▏       | 60/274 [00:07<00:34,  6.16it/s] 22%|██▏       | 61/274 [00:07<00:49,  4.26it/s] 23%|██▎       | 63/274 [00:08<00:39,  5.39it/s] 24%|██▎       | 65/274 [00:08<00:30,  6.82it/s] 24%|██▍       | 67/274 [00:08<00:27,  7.57it/s] 25%|██▌       | 69/274 [00:08<00:30,  6.72it/s] 26%|██▋       | 72/274 [00:08<00:23,  8.57it/s] 27%|██▋       | 74/274 [00:08<00:20,  9.67it/s] 28%|██▊       | 76/274 [00:09<00:24,  8.04it/s] 28%|██▊       | 78/274 [00:09<00:20,  9.36it/s] 29%|██▉       | 80/274 [00:09<00:18, 10.72it/s] 30%|██▉       | 82/274 [00:09<00:17, 11.26it/s] 31%|███       | 84/274 [00:09<00:17, 10.85it/s] 31%|███▏      | 86/274 [00:10<00:27,  6.79it/s] 32%|███▏      | 87/274 [00:10<00:30,  6.22it/s] 32%|███▏      | 88/274 [00:10<00:28,  6.57it/s] 33%|███▎      | 90/274 [00:11<00:26,  6.98it/s] 33%|███▎      | 91/274 [00:11<00:27,  6.75it/s] 34%|███▍      | 93/274 [00:11<00:21,  8.24it/s] 35%|███▍      | 95/274 [00:11<00:19,  9.03it/s] 35%|███▌      | 97/274 [00:11<00:25,  7.00it/s] 36%|███▌      | 98/274 [00:12<00:43,  4.07it/s] 36%|███▋      | 100/274 [00:12<00:32,  5.31it/s] 37%|███▋      | 102/274 [00:12<00:33,  5.16it/s] 38%|███▊      | 104/274 [00:13<00:26,  6.35it/s] 39%|███▊      | 106/274 [00:13<00:25,  6.66it/s] 39%|███▉      | 107/274 [00:13<00:28,  5.78it/s] 40%|███▉      | 109/274 [00:13<00:22,  7.30it/s] 41%|████      | 111/274 [00:13<00:18,  8.66it/s] 41%|████      | 113/274 [00:13<00:17,  9.34it/s] 42%|████▏     | 115/274 [00:14<00:14, 10.80it/s] 43%|████▎     | 117/274 [00:14<00:18,  8.66it/s] 43%|████▎     | 119/274 [00:14<00:20,  7.74it/s] 45%|████▍     | 123/274 [00:14<00:15,  9.75it/s] 46%|████▌     | 125/274 [00:15<00:15,  9.56it/s] 46%|████▋     | 127/274 [00:15<00:13, 11.28it/s] 47%|████▋     | 130/274 [00:15<00:12, 11.69it/s] 48%|████▊     | 132/274 [00:15<00:10, 13.33it/s] 49%|████▉     | 134/274 [00:15<00:14,  9.84it/s] 50%|█████     | 137/274 [00:16<00:11, 11.75it/s] 51%|█████     | 139/274 [00:16<00:12, 10.75it/s] 51%|█████▏    | 141/274 [00:16<00:13, 10.05it/s] 52%|█████▏    | 143/274 [00:16<00:11, 11.26it/s] 53%|█████▎    | 145/274 [00:16<00:10, 12.67it/s] 54%|█████▍    | 148/274 [00:17<00:22,  5.52it/s] 55%|█████▍    | 150/274 [00:18<00:21,  5.81it/s] 55%|█████▌    | 151/274 [00:18<00:27,  4.41it/s] 56%|█████▌    | 153/274 [00:18<00:21,  5.67it/s] 57%|█████▋    | 155/274 [00:18<00:18,  6.51it/s] 57%|█████▋    | 157/274 [00:19<00:16,  6.90it/s] 58%|█████▊    | 158/274 [00:19<00:21,  5.39it/s] 58%|█████▊    | 160/274 [00:19<00:17,  6.69it/s] 59%|█████▉    | 162/274 [00:19<00:17,  6.28it/s] 60%|██████    | 165/274 [00:20<00:14,  7.69it/s] 61%|██████▏   | 168/274 [00:20<00:13,  8.03it/s] 62%|██████▏   | 171/274 [00:20<00:10, 10.12it/s] 63%|██████▎   | 173/274 [00:20<00:11,  8.92it/s] 64%|██████▍   | 175/274 [00:21<00:17,  5.66it/s] 65%|██████▍   | 177/274 [00:21<00:15,  6.30it/s] 65%|██████▌   | 179/274 [00:22<00:14,  6.68it/s] 66%|██████▌   | 181/274 [00:22<00:13,  6.81it/s] 66%|██████▋   | 182/274 [00:22<00:19,  4.65it/s]{(1, 2): (0, 1), (2, 1): (1, 0), (2, 5): (0, 1), (5, 2): (1, 0), (17, 19): (1, 1), (17, 21): (1, 0), (21, 17): (0, 1), (19, 21): (1, 0), (21, 19): (0, 1), (52, 53): (1, 1)}
e1 e2 e1 5 19 5 (0, 1) (0, 1) (0, 1) said made NYT20000406.0002
e2 e1 e2 19 5 19 (1, 0) (1, 0) (1, 0) made said NYT20000406.0002
e2 e1 e2 19 5 19 (1, 0) (1, 0) (1, 0) made said NYT20000406.0002
e1 e2 e1 5 19 5 (0, 1) (0, 1) (0, 1) said made NYT20000406.0002
e2 e5 e2 19 18 19 (0, 1) (0, 1) (0, 1) made raised NYT20000406.0002
e5 e2 e5 18 19 18 (1, 0) (1, 0) (1, 0) raised made NYT20000406.0002
e5 e2 e5 18 19 18 (1, 0) (1, 0) (1, 0) raised made NYT20000406.0002
e2 e5 e2 19 18 19 (0, 1) (0, 1) (0, 1) made raised NYT20000406.0002
e17 e19 e17 5 24 5 (1, 1) (1, 1) (1, 1) left stir NYT20000406.0002
e17 e21 e17 5 14 5 (1, 0) (1, 0) (1, 0) left demanded NYT20000406.0002
e21 e17 e21 14 5 14 (0, 1) (0, 1) (0, 1) demanded left NYT20000406.0002
e21 e17 e21 14 5 14 (0, 1) (0, 1) (0, 1) demanded left NYT20000406.0002
e17 e21 e17 5 14 5 (1, 0) (1, 0) (1, 0) left demanded NYT20000406.0002
e19 e21 e19 24 14 24 (1, 0) (1, 0) (1, 0) stir demanded NYT20000406.0002
e21 e19 e21 14 24 14 (0, 1) (0, 1) (0, 1) demanded stir NYT20000406.0002
e21 e19 e21 14 24 14 (0, 1) (0, 1) (0, 1) demanded stir NYT20000406.0002
e19 e21 e19 24 14 24 (1, 0) (1, 0)  67%|██████▋   | 183/274 [00:22<00:17,  5.10it/s](1, 0) stir demanded NYT20000406.0002
e52 e53 e52 4 8 4 (1, 1) (1, 1) (1, 1) doing making NYT20000406.0002
 67%|██████▋   | 184/274 [00:23<00:28,  3.19it/s] 68%|██████▊   | 186/274 [00:23<00:20,  4.26it/s] 68%|██████▊   | 187/274 [00:23<00:25,  3.45it/s] 69%|██████▉   | 189/274 [00:24<00:18,  4.48it/s] 69%|██████▉   | 190/274 [00:24<00:16,  5.03it/s] 70%|███████   | 192/274 [00:24<00:13,  6.11it/s] 70%|███████   | 193/274 [00:24<00:12,  6.32it/s] 71%|███████   | 195/274 [00:24<00:11,  7.06it/s] 72%|███████▏  | 196/274 [00:24<00:10,  7.32it/s] 72%|███████▏  | 197/274 [00:25<00:09,  7.78it/s] 73%|███████▎  | 199/274 [00:25<00:07,  9.40it/s] 73%|███████▎  | 201/274 [00:25<00:09,  7.31it/s] 74%|███████▎  | 202/274 [00:25<00:09,  7.40it/s] 74%|███████▍  | 203/274 [00:25<00:11,  6.29it/s] 74%|███████▍  | 204/274 [00:26<00:14,  4.87it/s] 75%|███████▍  | 205/274 [00:27<00:27,  2.51it/s] 75%|███████▌  | 206/274 [00:27<00:24,  2.82it/s] 76%|███████▌  | 207/274 [00:27<00:23,  2.84it/s] 76%|███████▋  | 209/274 [00:27<00:18,  3.58it/s] 77%|███████▋  | 210/274 [00:27<00:15,  4.20it/s] 77%|███████▋  | 211/274 [00:28<00:13,  4.65it/s] 78%|███████▊  | 213/274 [00:28<00:12,  5.01it/s] 78%|███████▊  | 214/274 [00:28<00:15,  3.84it/s] 78%|███████▊  | 215/274 [00:29<00:27,  2.12it/s] 79%|███████▉  | 217/274 [00:30<00:20,  2.82it/s] 80%|███████▉  | 218/274 [00:31<00:32,  1.73it/s] 80%|████████  | 220/274 [00:31<00:25,  2.15it/s] 81%|████████  | 221/274 [00:31<00:20,  2.60it/s] 81%|████████  | 222/274 [00:31<00:15,  3.33it/s] 81%|████████▏ | 223/274 [00:31<00:12,  4.08it/s] 82%|████████▏ | 225/274 [00:32<00:10,  4.49it/s] 82%|████████▏ | 226/274 [00:32<00:13,  3.48it/s] 83%|████████▎ | 227/274 [00:32<00:11,  3.96it/s] 83%|████████▎ | 228/274 [00:33<00:11,  3.96it/s] 84%|████████▎ | 229/274 [00:33<00:13,  3.36it/s] 84%|████████▍ | 230/274 [00:33<00:11,  3.72it/s] 85%|████████▍ | 232/274 [00:33<00:09,  4.65it/s] 85%|████████▌ | 233/274 [00:34<00:14,  2.87it/s] 85%|████████▌ | 234/274 [00:34<00:13,  2.92it/s] 86%|████████▌ | 235/274 [00:35<00:12,  3.13it/s] 86%|████████▌ | 236/274 [00:35<00:10,  3.68it/s] 86%|████████▋ | 237/274 [00:35<00:08,  4.23it/s] 87%|████████▋ | 238/274 [00:36<00:20,  1.80it/s] 87%|████████▋ | 239/274 [00:36<00:15,  2.26it/s] 88%|████████▊ | 241/274 [00:37<00:13,  2.51it/s] 88%|████████▊ | 242/274 [00:37<00:12,  2.47it/s] 89%|████████▊ | 243/274 [00:38<00:10,  2.93it/s] 89%|████████▉ | 244/274 [00:38<00:09,  3.26it/s] 90%|████████▉ | 246/274 [00:38<00:06,  4.03it/s] 91%|█████████ | 248/274 [00:38<00:05,  4.41it/s] 91%|█████████ | 250/274 [00:39<00:05,  4.23it/s] 92%|█████████▏| 252/274 [00:39<00:04,  4.84it/s] 92%|█████████▏| 253/274 [00:39<00:04,  4.77it/s] 93%|█████████▎| 255/274 [00:40<00:03,  5.73it/s] 93%|█████████▎| 256/274 [00:40<00:02,  6.20it/s] 94%|█████████▍| 258/274 [00:40<00:02,  7.34it/s] 95%|█████████▍| 259/274 [00:40<00:02,  6.55it/s] 95%|█████████▍| 260/274 [00:40<00:01,  7.05it/s] 95%|█████████▌| 261/274 [00:40<00:02,  6.16it/s] 96%|█████████▌| 262/274 [00:41<00:01,  6.04it/s] 96%|█████████▌| 263/274 [00:41<00:01,  6.41it/s] 97%|█████████▋| 265/274 [00:41<00:01,  7.20it/s] 97%|█████████▋| 267/274 [00:41<00:01,  6.96it/s] 98%|█████████▊| 268/274 [00:41<00:00,  7.38it/s] 98%|█████████▊| 269/274 [00:42<00:00,  7.25it/s] 99%|█████████▊| 270/274 [00:43<00:01,  2.35it/s] 99%|█████████▉| 272/274 [00:43<00:00,  3.11it/s]100%|█████████▉| 273/274 [00:43<00:00,  3.64it/s]100%|██████████| 274/274 [00:43<00:00,  6.30it/s]
2021-07-05 14:54:50,223 [INFO] MATRES Preprocessing took 0:00:44
2021-07-05 14:54:50,223 [INFO] MATRES training instance num: 29500, valid instance num: 22892, test instance num: 2843
2021-07-05 14:54:50,224 [INFO] debug mode on
2021-07-05 14:54:52,116 [INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /Users/ehwang/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
2021-07-05 14:54:52,117 [INFO] Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_id": 2,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

2021-07-05 14:54:52,979 [INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /Users/ehwang/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Using OneThresholdEvaluator..!
2021-07-05 14:54:55,697 [INFO] ======== Epoch 1 / 10 ========
2021-07-05 14:54:55,697 [INFO] Training start...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [04:11<00:00, 251.97s/it]100%|██████████| 1/1 [04:11<00:00, 251.97s/it]
2021-07-05 14:59:07,672 [INFO] epoch: 1, loss: 225.100540
2021-07-05 14:59:07,675 [INFO] [valid-matres] start... 
2021-07-05 15:02:02,813 [INFO] confusion_matrix: 
[[ 2  0  0  0]
 [48  0  0  0]
 [47  0  0  0]
 [ 2  0  0  1]]
/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2021-07-05 15:02:02,825 [INFO] classifiction_report: 
              precision    recall  f1-score   support

          00       0.02      1.00      0.04         2
          01       0.00      0.00      0.00        48
          10       0.00      0.00      0.00        47
          11       1.00      0.33      0.50         3

    accuracy                           0.03       100
   macro avg       0.26      0.33      0.13       100
weighted avg       0.03      0.03      0.02       100

2021-07-05 15:02:02,825 [INFO] done!
2021-07-05 15:02:03,303 [INFO] # of 10 labels: 47
2021-07-05 15:02:03,497 [INFO] # of 01 labels: 48
2021-07-05 15:02:03,733 [INFO] # of 11 labels: 3
2021-07-05 15:02:03,907 [INFO] # of 00 labels: 2
2021-07-05 15:02:03,908 [INFO] [cv-valid-matres] start... 
Traceback (most recent call last):
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/__main__.py", line 261, in <module>
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/__main__.py", line 257, in main
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/train.py", line 158, in train
    self.evaluation(epoch)
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/train.py", line 182, in evaluation
    cv_valid_metrics.update(self.evaluator.evaluate("matres", "cv-valid"))
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/train.py", line 302, in evaluate
    vol_A_B, vol_B_A, vol_B_C, vol_C_B, vol_A_C, vol_C_A = self.model(batch, device, self.train_type) # [batch_size, 2]
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/model.py", line 385, in forward
    roberta_x_sntc = self._get_roberta_embedding(x_sntc) #[64, 120, 768];[batch_size, padded_len, roberta_dim]
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/model.py", line 375, in _get_roberta_embedding
    roberta_embd = self.RoBERTa_layer(s.unsqueeze(0))[0] # [1, 120, 768]
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 790, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 407, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 368, in forward
    self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 314, in forward
    hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 216, in forward
    mixed_query_layer = self.query(hidden_states)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
KeyboardInterrupt
