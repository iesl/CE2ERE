2021-07-05 14:45:26,447 [INFO] {'data_dir': '../data', 'no_cuda': False, 'debug': True, 'log_batch_size': 7, 'epochs': 10, 'data_type': 'matres', 'finetune': False, 'model': 'box', 'downsample': 0.001, 'learning_rate': 0.01, 'lambda_anno': 1.0, 'lambda_trans': 0.0, 'lambda_cross': 0.0, 'volume_temp': 1.0, 'intersection_temp': 0.0001, 'hieve_threshold': -0.6, 'matres_threshold': -0.5, 'mlp_size': 32, 'mlp_output_dim': 32, 'hieve_mlp_size': 64, 'matres_mlp_size': 32, 'proj_output_dim': 32, 'num_layers': 1, 'roberta_hidden_size': 1024, 'lstm_hidden_size': 256, 'lstm_input_size': 768, 'no_valid': False, 'loss_type': 0, 'patience': 8, 'eval_step': 1, 'eval_type': 'one', 'load_model': 0, 'saved_model': '/Users/ehwang/PycharmProjects/CE2ERE/src/model/matres_20210505163300_2ya6wb7v.pt', 'wandb_id': 'hwang7520/CE2ERE-src/2ya6wb7v', 'load_valid': 0, 'save_plot': 1, 'symm_eval': 1}
2021-07-05 14:45:26,447 [INFO] Requested CUDA but it is not available, running on CPU
  0%|          | 0/274 [00:00<?, ?it/s]  0%|          | 1/274 [00:00<00:52,  5.17it/s]  1%|          | 3/274 [00:00<00:48,  5.64it/s]  2%|▏         | 5/274 [00:00<00:38,  7.04it/s]  3%|▎         | 7/274 [00:00<00:37,  7.21it/s]  3%|▎         | 9/274 [00:01<00:32,  8.09it/s]  4%|▍         | 11/274 [00:01<00:56,  4.64it/s]  4%|▍         | 12/274 [00:02<00:57,  4.57it/s]  5%|▌         | 14/274 [00:02<00:44,  5.79it/s]  5%|▌         | 15/274 [00:02<00:40,  6.45it/s]  6%|▌         | 17/274 [00:02<00:32,  7.80it/s]  7%|▋         | 20/274 [00:02<00:27,  9.30it/s]  8%|▊         | 23/274 [00:02<00:22, 11.10it/s]  9%|▉         | 25/274 [00:03<00:24,  9.99it/s] 10%|▉         | 27/274 [00:03<00:25,  9.51it/s] 11%|█         | 29/274 [00:03<00:28,  8.73it/s] 11%|█▏        | 31/274 [00:03<00:32,  7.39it/s] 12%|█▏        | 32/274 [00:04<00:43,  5.55it/s] 12%|█▏        | 34/274 [00:04<00:36,  6.64it/s] 14%|█▎        | 37/274 [00:04<00:27,  8.57it/s] 14%|█▍        | 39/274 [00:04<00:23,  9.89it/s] 15%|█▍        | 41/274 [00:04<00:25,  8.99it/s] 16%|█▌        | 44/274 [00:05<00:20, 11.03it/s] 17%|█▋        | 46/274 [00:05<00:19, 11.46it/s] 18%|█▊        | 48/274 [00:05<00:20, 11.15it/s] 18%|█▊        | 50/274 [00:05<00:17, 12.71it/s] 19%|█▉        | 53/274 [00:06<00:26,  8.32it/s] 20%|██        | 55/274 [00:06<00:30,  7.22it/s] 21%|██        | 57/274 [00:06<00:34,  6.31it/s] 22%|██▏       | 59/274 [00:07<00:34,  6.18it/s] 22%|██▏       | 60/274 [00:07<00:32,  6.56it/s] 22%|██▏       | 61/274 [00:07<00:48,  4.38it/s] 23%|██▎       | 63/274 [00:07<00:38,  5.49it/s] 24%|██▎       | 65/274 [00:08<00:30,  6.91it/s] 24%|██▍       | 67/274 [00:08<00:27,  7.63it/s] 25%|██▌       | 69/274 [00:08<00:30,  6.75it/s] 26%|██▋       | 72/274 [00:08<00:23,  8.60it/s] 27%|██▋       | 74/274 [00:08<00:20,  9.75it/s] 28%|██▊       | 76/274 [00:09<00:24,  7.95it/s] 28%|██▊       | 78/274 [00:09<00:21,  9.16it/s] 29%|██▉       | 80/274 [00:09<00:18, 10.49it/s] 30%|██▉       | 82/274 [00:09<00:17, 10.94it/s] 31%|███       | 84/274 [00:09<00:17, 10.66it/s] 31%|███▏      | 86/274 [00:10<00:27,  6.77it/s] 32%|███▏      | 87/274 [00:10<00:29,  6.26it/s] 32%|███▏      | 88/274 [00:10<00:28,  6.63it/s] 33%|███▎      | 90/274 [00:10<00:26,  6.99it/s] 33%|███▎      | 91/274 [00:11<00:25,  7.19it/s] 34%|███▍      | 93/274 [00:11<00:20,  8.74it/s] 35%|███▍      | 95/274 [00:11<00:19,  9.32it/s] 35%|███▌      | 97/274 [00:11<00:23,  7.63it/s] 36%|███▌      | 98/274 [00:12<00:36,  4.77it/s] 37%|███▋      | 101/274 [00:12<00:31,  5.47it/s] 37%|███▋      | 102/274 [00:12<00:28,  6.12it/s] 38%|███▊      | 104/274 [00:12<00:22,  7.47it/s] 39%|███▊      | 106/274 [00:13<00:22,  7.46it/s] 39%|███▉      | 107/274 [00:13<00:26,  6.19it/s] 40%|███▉      | 109/274 [00:13<00:21,  7.71it/s] 41%|████      | 111/274 [00:13<00:17,  9.06it/s] 41%|████      | 113/274 [00:13<00:16,  9.65it/s] 42%|████▏     | 115/274 [00:13<00:14, 11.11it/s] 43%|████▎     | 117/274 [00:14<00:17,  8.86it/s] 43%|████▎     | 119/274 [00:14<00:19,  7.84it/s] 45%|████▍     | 122/274 [00:14<00:15, 10.07it/s] 45%|████▌     | 124/274 [00:14<00:16,  9.37it/s] 46%|████▋     | 127/274 [00:14<00:13, 11.03it/s] 47%|████▋     | 129/274 [00:15<00:11, 12.47it/s] 48%|████▊     | 131/274 [00:15<00:12, 11.61it/s] 49%|████▊     | 133/274 [00:15<00:11, 12.27it/s] 49%|████▉     | 135/274 [00:15<00:14,  9.83it/s] 50%|█████     | 138/274 [00:16<00:13,  9.82it/s] 51%|█████▏    | 141/274 [00:16<00:13,  9.90it/s] 52%|█████▏    | 143/274 [00:16<00:11, 11.11it/s] 53%|█████▎    | 145/274 [00:16<00:10, 12.25it/s] 54%|█████▍    | 148/274 [00:17<00:24,  5.24it/s] 55%|█████▍    | 150/274 [00:18<00:21,  5.70it/s] 55%|█████▌    | 151/274 [00:18<00:27,  4.44it/s] 56%|█████▌    | 153/274 [00:18<00:21,  5.71it/s] 57%|█████▋    | 155/274 [00:18<00:18,  6.51it/s] 57%|█████▋    | 157/274 [00:19<00:17,  6.76it/s] 58%|█████▊    | 158/274 [00:19<00:22,  5.15it/s] 58%|█████▊    | 160/274 [00:19<00:17,  6.40it/s] 59%|█████▉    | 161/274 [00:19<00:23,  4.73it/s] 59%|█████▉    | 163/274 [00:20<00:18,  6.11it/s] 60%|██████    | 165/274 [00:20<00:15,  7.25it/s] 61%|██████▏   | 168/274 [00:20<00:14,  7.53it/s] 62%|██████▏   | 171/274 [00:20<00:10,  9.45it/s] 63%|██████▎   | 173/274 [00:20<00:12,  8.26it/s] 64%|██████▍   | 175/274 [00:21<00:18,  5.22it/s] 65%|██████▍   | 177/274 [00:21<00:16,  5.91it/s] 65%|██████▌   | 179/274 [00:22<00:14,  6.34it/s] 66%|██████▌   | 181/274 [00:22<00:14,  6.51it/s] 66%|██████▋   | 182/274 [00:22<00:20,  4.45it/s]{(1, 2): (0, 1), (2, 1): (1, 0), (2, 5): (0, 1), (5, 2): (1, 0), (17, 19): (1, 1), (17, 21): (1, 0), (21, 17): (0, 1), (19, 21): (1, 0), (21, 19): (0, 1), (52, 53): (1, 1)}
e1 e2 e1 5 19 5 (0, 1) (0, 1) (0, 1) said made NYT20000406.0002
e2 e1 e2 19 5 19 (1, 0) (1, 0) (1, 0) made said NYT20000406.0002
e2 e1 e2 19 5 19 (1, 0) (1, 0) (1, 0) made said NYT20000406.0002
e1 e2 e1 5 19 5 (0, 1) (0, 1) (0, 1) said made NYT20000406.0002
e2 e5 e2 19 18 19 (0, 1) (0, 1) (0, 1) made raised NYT20000406.0002
e5 e2 e5 18 19 18 (1, 0) (1, 0) (1, 0) raised made NYT20000406.0002
e5 e2 e5 18 19 18 (1, 0) (1, 0) (1, 0) raised made NYT20000406.0002
e2 e5 e2 19 18 19 (0, 1) (0, 1) (0, 1) made raised NYT20000406.0002
e17 e19 e17 5 24 5 (1, 1) (1, 1) (1, 1) left stir NYT20000406.0002
e17 e21 e17 5 14 5 (1, 0) (1, 0) (1, 0) left demanded NYT20000406.0002
e21 e17 e21 14 5 14 (0, 1) (0, 1) (0, 1) demanded left NYT20000406.0002
e21 e17 e21 14 5 14 (0, 1) (0, 1) (0, 1) demanded left NYT20000406.0002
e17 e21 e17 5 14 5 (1, 0) (1, 0) (1, 0) left demanded NYT20000406.0002
e19 e21 e19 24 14 24 (1, 0) (1, 0) (1, 0) stir demanded NYT20000406.0002
e21 e19 e21 14 24 14 (0, 1) (0, 1) (0, 1) demanded stir NYT20000406.0002
e21 e19 e21 14 24 14 (0, 1) (0, 1) (0, 1) demanded stir NYT20000406.0002
e19 e21 e19 24 14 24 (1, 0) (1, 0) (1, 0) stir demanded NYT20000406.0002
e52 e53 e52 4 8 4 (1, 1) (1, 1) (1, 1) doing making 67%|██████▋   | 183/274 [00:23<00:18,  4.85it/s] NYT20000406.0002
 67%|██████▋   | 184/274 [00:23<00:30,  2.94it/s] 68%|██████▊   | 186/274 [00:23<00:22,  3.87it/s] 68%|██████▊   | 187/274 [00:24<00:27,  3.20it/s] 69%|██████▉   | 189/274 [00:24<00:20,  4.17it/s] 69%|██████▉   | 190/274 [00:24<00:17,  4.81it/s] 70%|███████   | 192/274 [00:24<00:14,  5.85it/s] 70%|███████   | 193/274 [00:24<00:12,  6.31it/s] 71%|███████   | 195/274 [00:25<00:11,  7.02it/s] 72%|███████▏  | 196/274 [00:25<00:10,  7.37it/s] 72%|███████▏  | 197/274 [00:25<00:10,  7.68it/s] 73%|███████▎  | 199/274 [00:25<00:08,  9.14it/s] 73%|███████▎  | 201/274 [00:25<00:10,  7.05it/s] 74%|███████▎  | 202/274 [00:25<00:09,  7.25it/s] 74%|███████▍  | 203/274 [00:26<00:11,  6.17it/s] 74%|███████▍  | 204/274 [00:26<00:14,  4.87it/s] 75%|███████▍  | 205/274 [00:27<00:29,  2.37it/s] 75%|███████▌  | 206/274 [00:27<00:25,  2.62it/s] 76%|███████▌  | 207/274 [00:28<00:24,  2.72it/s] 76%|███████▋  | 209/274 [00:28<00:18,  3.46it/s] 77%|███████▋  | 210/274 [00:28<00:15,  4.11it/s] 77%|███████▋  | 211/274 [00:28<00:13,  4.62it/s] 78%|███████▊  | 213/274 [00:28<00:12,  5.07it/s] 78%|███████▊  | 214/274 [00:29<00:15,  3.94it/s] 78%|███████▊  | 215/274 [00:30<00:26,  2.23it/s] 79%|███████▉  | 217/274 [00:30<00:19,  2.96it/s] 80%|███████▉  | 218/274 [00:31<00:30,  1.85it/s] 80%|████████  | 220/274 [00:31<00:23,  2.29it/s] 81%|████████  | 221/274 [00:31<00:19,  2.76it/s] 81%|████████▏ | 223/274 [00:32<00:14,  3.50it/s] 82%|████████▏ | 225/274 [00:32<00:12,  3.97it/s] 82%|████████▏ | 226/274 [00:32<00:14,  3.27it/s] 83%|████████▎ | 227/274 [00:33<00:12,  3.84it/s] 83%|████████▎ | 228/274 [00:33<00:11,  4.00it/s] 84%|████████▎ | 229/274 [00:33<00:13,  3.46it/s] 84%|████████▍ | 230/274 [00:33<00:11,  3.88it/s] 85%|████████▍ | 232/274 [00:33<00:08,  4.85it/s] 85%|████████▌ | 233/274 [00:34<00:13,  3.05it/s] 85%|████████▌ | 234/274 [00:34<00:12,  3.10it/s] 86%|████████▌ | 235/274 [00:35<00:11,  3.37it/s] 86%|████████▌ | 236/274 [00:35<00:09,  3.98it/s] 86%|████████▋ | 237/274 [00:35<00:07,  4.64it/s] 87%|████████▋ | 238/274 [00:36<00:18,  2.00it/s] 87%|████████▋ | 239/274 [00:36<00:13,  2.51it/s] 88%|████████▊ | 241/274 [00:37<00:12,  2.72it/s] 88%|████████▊ | 242/274 [00:37<00:12,  2.57it/s] 89%|████████▊ | 243/274 [00:37<00:10,  3.05it/s] 89%|████████▉ | 244/274 [00:38<00:08,  3.38it/s] 90%|████████▉ | 246/274 [00:38<00:06,  4.15it/s] 91%|█████████ | 248/274 [00:38<00:05,  4.53it/s] 91%|█████████ | 249/274 [00:38<00:04,  5.40it/s] 91%|█████████ | 250/274 [00:39<00:06,  3.94it/s] 92%|█████████▏| 252/274 [00:39<00:04,  4.54it/s] 92%|█████████▏| 253/274 [00:39<00:04,  4.54it/s] 93%|█████████▎| 255/274 [00:39<00:03,  5.45it/s] 93%|█████████▎| 256/274 [00:40<00:03,  5.94it/s] 94%|█████████▍| 257/274 [00:40<00:02,  6.74it/s] 95%|█████████▍| 259/274 [00:40<00:02,  6.98it/s] 95%|█████████▍| 260/274 [00:40<00:01,  7.43it/s] 95%|█████████▌| 261/274 [00:40<00:02,  6.36it/s] 96%|█████████▌| 262/274 [00:40<00:02,  5.98it/s] 96%|█████████▌| 263/274 [00:41<00:01,  6.40it/s] 97%|█████████▋| 265/274 [00:41<00:01,  7.13it/s] 97%|█████████▋| 267/274 [00:41<00:01,  6.84it/s] 98%|█████████▊| 268/274 [00:41<00:00,  7.23it/s] 98%|█████████▊| 269/274 [00:41<00:00,  6.96it/s] 99%|█████████▊| 270/274 [00:43<00:01,  2.35it/s] 99%|█████████▉| 272/274 [00:43<00:00,  3.09it/s]100%|█████████▉| 273/274 [00:43<00:00,  3.54it/s]100%|██████████| 274/274 [00:43<00:00,  6.31it/s]
2021-07-05 14:46:09,906 [INFO] MATRES Preprocessing took 0:00:43
2021-07-05 14:46:09,906 [INFO] MATRES training instance num: 29500, valid instance num: 22892, test instance num: 2843
2021-07-05 14:46:09,906 [INFO] debug mode on
2021-07-05 14:46:11,830 [INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /Users/ehwang/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690
2021-07-05 14:46:11,830 [INFO] Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_id": 2,
  "eos_token_ids": null,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

2021-07-05 14:46:12,734 [INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /Users/ehwang/.cache/torch/transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e
Using OneThresholdEvaluator..!
2021-07-05 14:46:15,614 [INFO] ======== Epoch 1 / 10 ========
2021-07-05 14:46:15,614 [INFO] Training start...
  0%|          | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/__main__.py", line 261, in <module>
    main()
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/__main__.py", line 257, in main
    trainer.train()
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/train.py", line 110, in train
    vol_A_B, vol_B_A, _, _, _, _ = self.model(batch, device, self.data_type) # [batch_size, # of datasets]
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/model.py", line 385, in forward
    roberta_x_sntc = self._get_roberta_embedding(x_sntc) #[64, 120, 768];[batch_size, padded_len, roberta_dim]
  File "/Users/ehwang/PycharmProjects/CE2ERE/src/model.py", line 375, in _get_roberta_embedding
    roberta_embd = self.RoBERTa_layer(s.unsqueeze(0))[0] # [1, 120, 768]
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 790, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 407, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 368, in forward
    self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 314, in forward
    hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/Users/ehwang/opt/anaconda3/envs/conda-env/lib/python3.7/site-packages/transformers/modeling_bert.py", line 248, in forward
    if head_mask is not None:
KeyboardInterrupt
  0%|          | 0/1 [01:04<?, ?it/s]
